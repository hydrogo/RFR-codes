{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../models/\")\n",
    "from baseflow import baseflow_separation\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"/home/georgy/Documents/PEAK/results/tier2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snow_driven_or_not(states_instance):\n",
    "    \n",
    "    snowpack = states_instance[\"snowpack\"].to_numpy()\n",
    "    \n",
    "    diffs = np.diff(np.flatnonzero(snowpack))\n",
    "    \n",
    "    periods = []\n",
    "    \n",
    "    length=0\n",
    "    \n",
    "    for i in range(1, len(diffs)):\n",
    "        \n",
    "        if diffs[i]==1:\n",
    "            \n",
    "            length = length + 1\n",
    "            \n",
    "            if i == len(diffs)-1:\n",
    "                \n",
    "                periods.append(length)\n",
    "        \n",
    "        else:\n",
    "            periods.append(length)\n",
    "            lenght = 0\n",
    "    \n",
    "    if np.any(np.array(periods)>30):\n",
    "        snow_driven=True\n",
    "    else:\n",
    "        snow_driven=False\n",
    "    \n",
    "    return snow_driven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_period_delineation(arr, threshold=0.1, duration=28):\n",
    "    \n",
    "    first=0\n",
    "    last=0\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        \n",
    "        if np.all(arr[i:i+duration]>threshold):\n",
    "            \n",
    "            first=i\n",
    "            break\n",
    "    \n",
    "    for j in range(duration+1, 365-first):\n",
    "        \n",
    "        if np.all(arr[first:first+j]>threshold):\n",
    "            \n",
    "            last=first+j\n",
    "    \n",
    "    maxd = np.argmax(arr[first:last]) + first\n",
    "    \n",
    "    return first, last, maxd\n",
    "\n",
    "def flood_period_delineation2(arr, threshold=0.5):\n",
    "    \n",
    "    positive_indexes = np.flatnonzero(arr>threshold)\n",
    "    \n",
    "    if len(positive_indexes) == 0:\n",
    "        threshold = 0.1\n",
    "        positive_indexes = np.flatnonzero(arr>threshold)\n",
    "        \n",
    "        if len(positive_indexes) == 0:\n",
    "            threshold = 0.01\n",
    "            positive_indexes = np.flatnonzero(arr>threshold)\n",
    "            \n",
    "            if len(positive_indexes) == 0:\n",
    "                threshold = 0.\n",
    "                positive_indexes = np.flatnonzero(arr>threshold)\n",
    "        \n",
    "    \n",
    "    diffs = np.diff(positive_indexes)\n",
    "    # marker of the end of the diffs to locate the last interval\n",
    "    diffs = np.append(diffs, 999)\n",
    "    \n",
    "    lengths = []\n",
    "    firsts = []\n",
    "    lasts = []\n",
    "    \n",
    "    periods = []\n",
    "    \n",
    "    length=0\n",
    "    first=positive_indexes[0]\n",
    "    last=positive_indexes[0]\n",
    "    \n",
    "    for i in range(0, len(diffs)):\n",
    "        \n",
    "        if diffs[i]==1:\n",
    "            \n",
    "            length = length + 1\n",
    "            last = last + 1\n",
    "        \n",
    "        else:\n",
    "            lengths.append(length)\n",
    "            firsts.append(first)\n",
    "            lasts.append(last)\n",
    "            periods.append([length, first, last])\n",
    "            \n",
    "            if i < len(diffs)-1: # not the last\n",
    "                length = 0\n",
    "                first=positive_indexes[i+1]\n",
    "                last=positive_indexes[i+1]\n",
    "            else: # the last value\n",
    "                break\n",
    "    \n",
    "    max_dur_period = np.argmax(lengths)\n",
    "    \n",
    "    if firsts[max_dur_period] >=2:\n",
    "        first = firsts[max_dur_period] - 2 # manual adjusting for higher threshold\n",
    "    else:\n",
    "        first = firsts[max_dur_period]\n",
    "    \n",
    "    last = lasts[max_dur_period]\n",
    "    \n",
    "    maxd = np.argmax(arr[first:last]) + first\n",
    "    \n",
    "    return first, last, maxd, periods\n",
    "\n",
    "\n",
    "def baseflow_updater(baseflow_sep_instance, start, end, maxd):\n",
    "    \n",
    "    baseflow_sep_instance[\"Baseflow\"] = baseflow_sep_instance[\"Baseflow_3\"].copy()\n",
    "    \n",
    "    baseflow_sep_instance[\"Baseflow\"].iloc[start:end] = np.nan\n",
    "    \n",
    "    baseflow_sep_instance[\"Baseflow\"].iloc[maxd] = 0\n",
    "    \n",
    "    baseflow_sep_instance[\"Baseflow\"] = baseflow_sep_instance[\"Baseflow\"].interpolate()\n",
    "    \n",
    "    return baseflow_sep_instance.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_characteristics(baseflow_sep_instance, spring_flood=True):\n",
    "    \n",
    "    if spring_flood:\n",
    "    \n",
    "        quickflow = (baseflow_sep_instance[\"Streamflow\"] - baseflow_sep_instance[\"Baseflow_3\"]).to_numpy()\n",
    "\n",
    "        # sf for spring flood\n",
    "        sf_start, sf_end, sf_maxd, periods = flood_period_delineation2(quickflow) ###!!!! changed to \"2\" option\n",
    "\n",
    "        # duration\n",
    "        sf_dur = sf_end-sf_start\n",
    "\n",
    "        # update Baseflow based on Russian theoretical studies (also in GrWAT)\n",
    "        baseflow_sep_instance_upd = baseflow_updater(baseflow_sep_instance, sf_start, sf_end, sf_maxd)\n",
    "\n",
    "        # sf runoff\n",
    "        sf_Q = baseflow_sep_instance_upd[\"Streamflow\"].iloc[sf_start:sf_end].copy()\n",
    "\n",
    "        # total flood volume\n",
    "        sf_vol = sf_Q.sum()\n",
    "\n",
    "        # max runoff\n",
    "        sf_maxQ = sf_Q.max()\n",
    "\n",
    "        # prominent peaks\n",
    "        sf_peaks, _ = find_peaks(sf_Q.to_numpy(), prominence=1)\n",
    "\n",
    "        # number of prominent peaks\n",
    "        sf_peaks_num = len(sf_peaks)\n",
    "\n",
    "        # magnitude\n",
    "        sf_mgn = sf_Q.max() - sf_Q.min()\n",
    "\n",
    "        # ratio of sf volume in total flow\n",
    "        sf_vol_ratio = sf_vol / baseflow_sep_instance_upd[\"Streamflow\"].sum()\n",
    "        \n",
    "        # baseflow index (ratio of baseflow vol in total runoff)\n",
    "        bfi = baseflow_sep_instance_upd[\"Baseflow\"].sum() / baseflow_sep_instance_upd[\"Streamflow\"].sum()\n",
    "        \n",
    "        sf_characteristics = [sf_start, sf_end, sf_dur, sf_vol, sf_vol_ratio,\n",
    "                              sf_maxQ, sf_maxd, sf_peaks_num, sf_mgn, bfi]\n",
    "        \n",
    "        sf_characteristics_names = [\"sf_start\", \"sf_end\", \"sf_dur\", \"sf_vol\", \"sf_vol_ratio\",\n",
    "                                    \"sf_maxQ\", \"sf_maxd\", \"sf_peaks_num\", \"sf_mgn\", \"bfi\"]\n",
    "        \n",
    "        ##########################################################################\n",
    "        # rf for rain flood\n",
    "        rf_dates = [False if (i > sf_start) and (i<sf_end) else True for i in range(len(quickflow))]\n",
    "        \n",
    "        # rain flood total volume \n",
    "        rf_vol = np.nansum(quickflow[rf_dates])\n",
    "        \n",
    "        # ration of rf in total flow\n",
    "        rf_vol_ratio = rf_vol / baseflow_sep_instance_upd[\"Streamflow\"].sum()\n",
    "        \n",
    "        # rf maxQ\n",
    "        rf_maxQ = baseflow_sep_instance_upd[\"Streamflow\"].iloc[rf_dates].max()\n",
    "        \n",
    "        # date of the max rain-induced flood\n",
    "        rf_maxd = np.flatnonzero(baseflow_sep_instance_upd[\"Streamflow\"] == rf_maxQ)[0]\n",
    "        \n",
    "        # peaks of rainfall-induced floods \n",
    "        rf_peaks, _ = find_peaks(baseflow_sep_instance_upd[\"Streamflow\"].to_numpy(), prominence=0.1)\n",
    "        \n",
    "        # exclude peaks relevant to spring flood\n",
    "        rf_peaks = [i for i in rf_peaks if i not in range(sf_start, sf_end+1)]\n",
    "        \n",
    "        # number of rf peaks\n",
    "        rf_peaks_num = len(rf_peaks)\n",
    "        \n",
    "        # rainfall-induced flood periods (same threshold for spring flood)\n",
    "        rf_periods = periods.copy()\n",
    "        \n",
    "        if len(rf_periods)>=2:\n",
    "            rf_periods_lengths = [i[0] for i in rf_periods]\n",
    "\n",
    "            # remove the spring flood period\n",
    "            _ = rf_periods.pop(np.argmax(rf_periods_lengths))\n",
    "\n",
    "            # updates period lengths\n",
    "            rf_durations = np.array([i[0] for i in rf_periods])\n",
    "\n",
    "            rf_periods_number = len(rf_durations)\n",
    "\n",
    "            rf_duration_max = rf_durations.max()\n",
    "            rf_duration_min = rf_durations.min()\n",
    "            rf_duration_mean = rf_durations.mean()\n",
    "            \n",
    "        else:\n",
    "            rf_periods_number = 0\n",
    "            rf_duration_max = 0\n",
    "            rf_duration_min = 0\n",
    "            rf_duration_mean = 0\n",
    "        \n",
    "        rf_characteristics = [rf_vol, rf_vol_ratio, rf_maxQ, rf_maxd, rf_peaks_num, rf_periods_number,\n",
    "                              rf_duration_max, rf_duration_min, rf_duration_mean]\n",
    "        \n",
    "        rf_characteristics_names = [\"rf_vol\", \"rf_vol_ratio\", \"rf_maxQ\", \"rf_maxd\", \"rf_peaks_num\", \n",
    "                                    \"rf_periods_number\", \"rf_duration_max\", \"rf_duration_min\", \"rf_duration_mean\"]\n",
    "        \n",
    "        #################################################################\n",
    "        # misc\n",
    "        \n",
    "        # we have ration of baseflow in total, \n",
    "        # and we have a ration of rain-induced quickflow\n",
    "        # so, we need spring-flood-induced ratio.\n",
    "        # it will be different from sf_vol_ratio \n",
    "        # because sf_vol was calculated WITH baseflow\n",
    "        \n",
    "        sf_ratio = 1 - bfi - rf_vol_ratio\n",
    "        \n",
    "        # mean annual runoff\n",
    "        mar = baseflow_sep_instance_upd[\"Streamflow\"].mean()\n",
    "        \n",
    "        misc_characterstics = [sf_ratio, mar]\n",
    "        \n",
    "        misc_characterstics_names = [\"sf_ratio\", \"mar\"]\n",
    "        \n",
    "        characteristics = sf_characteristics + rf_characteristics + misc_characterstics\n",
    "        \n",
    "        characteristics_names = sf_characteristics_names + rf_characteristics_names + misc_characterstics_names\n",
    "        \n",
    "        return characteristics, characteristics_names\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        quickflow = baseflow_sep_instance[\"Streamflow\"] - baseflow_sep_instance[\"Baseflow_3\"]\n",
    "        \n",
    "        # the ratio of\n",
    "        flood_ratio = quickflow.sum() / baseflow_sep_instance[\"Streamflow\"].sum()\n",
    "        \n",
    "        # bfi\n",
    "        bfi = baseflow_sep_instance[\"Baseflow_3\"].sum() / baseflow_sep_instance[\"Streamflow\"].sum()\n",
    "    \n",
    "        # number of peaks\n",
    "        peaks, _ = find_peaks(baseflow_sep_instance[\"Streamflow\"].to_numpy(), prominence=0.1)\n",
    "        peaks_num = len(peaks)\n",
    "        \n",
    "        # maximum flow\n",
    "        maxQ = baseflow_sep_instance[\"Streamflow\"].max()\n",
    "        \n",
    "        # the date of maximum flow\n",
    "        maxd = np.flatnonzero(baseflow_sep_instance[\"Streamflow\"] == maxQ)[0]\n",
    "        \n",
    "        # magnitude\n",
    "        mgn = baseflow_sep_instance[\"Streamflow\"].max() - baseflow_sep_instance[\"Streamflow\"].min()\n",
    "        \n",
    "        # flood periods\n",
    "        _,_,_,fl_periods = flood_period_delineation2(quickflow, threshold=0.5)\n",
    "        \n",
    "        # number of flood periods\n",
    "        fl_periods_number = len(fl_periods)\n",
    "        \n",
    "        # duration of flood periods\n",
    "        fl_durations = np.array([i[0] for i in fl_periods])\n",
    "        \n",
    "        # max, min, mean\n",
    "        fl_duration_max = fl_durations.max()\n",
    "        fl_duration_min = fl_durations.min()\n",
    "        fl_duration_mean = fl_durations.mean()\n",
    "        \n",
    "        # mean annual runoff\n",
    "        mar = baseflow_sep_instance[\"Streamflow\"].mean()\n",
    "               \n",
    "        fl_characteristics = [flood_ratio, bfi, peaks_num, maxQ, maxd, mgn, \n",
    "                              fl_periods_number, fl_duration_max, fl_duration_min, \n",
    "                              fl_duration_mean, mar]\n",
    "        \n",
    "        fl_characteristics_names = [\"flood_ratio\", \"bfi\", \"peaks_num\", \"maxQ\", \"maxd\", \"mgn\",\n",
    "                                    \"fl_periods_number\", \"fl_duration_max\", \"fl_duration_min\",\n",
    "                                    \"fl_duration_mean\", \"mar\"]\n",
    "        \n",
    "        return fl_characteristics, fl_characteristics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_characteristics(basin_id, mode=\"HST\", model=\"MIROC5\", scenario=\"rcp26\"):\n",
    "    \n",
    "    if mode == \"HST\":\n",
    "        \n",
    "        # define years to consider\n",
    "        years = [str(i) for i in range(1979,2017)]\n",
    "        \n",
    "        path_runoff = os.path.join(path_to_dataset, \"hydro/runoff/\", mode, f\"{basin_id}.csv\")\n",
    "        path_states = os.path.join(path_to_dataset, \"hydro/states/\", mode, f\"{basin_id}.csv\")\n",
    "        \n",
    "    elif mode == \"PRJ\":\n",
    "        \n",
    "        # define years to consider\n",
    "        years = [str(i) for i in range(2016,2100)]\n",
    "        \n",
    "        path_runoff = os.path.join(path_to_dataset, \"hydro/runoff/\", mode, model, scenario, f\"{basin_id}.csv\")\n",
    "        path_states = os.path.join(path_to_dataset, \"hydro/states/\", mode, model, scenario, f\"{basin_id}.csv\")\n",
    "        \n",
    "    # read input data\n",
    "    runoff = pd.read_csv(path_runoff, \n",
    "                         index_col=0, \n",
    "                         parse_dates=True)\n",
    "\n",
    "    states = pd.read_csv(path_states, \n",
    "                         index_col=0, \n",
    "                         parse_dates=True)\n",
    "\n",
    "    # clip to historical period\n",
    "    runoff = runoff[years[0]:years[-1]].copy()\n",
    "    states = states[years[0]:years[-1]].copy()\n",
    "\n",
    "    # hydrograph separation on quick- and baseflow\n",
    "    baseflow_sep = baseflow_separation(runoff[\"Runoff\"].copy())\n",
    "\n",
    "    holder_snowdriven = {}\n",
    "    holder_raindriven = {}\n",
    "\n",
    "    cols_snowdriven = []\n",
    "    cols_raindriven = []\n",
    "\n",
    "    for year in years[1:]: # start from the first year + 1, e.g. 1980 *water* year\n",
    "        \n",
    "        #print(year)\n",
    "        \n",
    "        year = int(year)\n",
    "\n",
    "        snow_driven = snow_driven_or_not(states[f\"{year-1}-11-01\":f\"{year}-10-31\"]) # 1 Nov -- 31 Oct\n",
    "\n",
    "        characteristics, characteristics_names = flood_characteristics(baseflow_sep[f\"{year-1}-11-01\":f\"{year}-10-31\"], snow_driven)\n",
    "\n",
    "        if snow_driven:\n",
    "\n",
    "            holder_snowdriven[year] = characteristics\n",
    "            cols_snowdriven = characteristics_names\n",
    "\n",
    "        else:\n",
    "\n",
    "            holder_raindriven[year] = characteristics\n",
    "            cols_raindriven = characteristics_names\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # convertion to pandas dataframes\n",
    "    \n",
    "    if len(holder_snowdriven)>0:\n",
    "        df_snowdriven = pd.DataFrame(holder_snowdriven, index=cols_snowdriven).T\n",
    "        output.append(df_snowdriven)\n",
    "    else:\n",
    "        output.append(pd.DataFrame())\n",
    "\n",
    "    if len(holder_raindriven)>0:\n",
    "        df_raindriven = pd.DataFrame(holder_raindriven, index=cols_raindriven).T\n",
    "        output.append(df_raindriven)\n",
    "    else:\n",
    "        output.append(pd.DataFrame())\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 2.8 ms, total: 1.77 s\n",
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nvkz_sd, nvkz_rd = calculate_characteristics(10240, mode=\"HST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.83 s, sys: 3.56 ms, total: 3.83 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nvkz_sdf, nvkz_rdf = calculate_characteristics(10240, mode=\"PRJ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
